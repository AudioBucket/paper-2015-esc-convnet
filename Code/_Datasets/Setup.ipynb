{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('style.css')</style><script>IPython.OutputArea.prototype._should_scroll = function(){return false}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>@import url('style.css')</style><script>IPython.OutputArea.prototype._should_scroll = function(){return false}</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common methods for dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pydub\n",
    "\n",
    "import IPython.display\n",
    "import cPickle\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "sb.set(style=\"white\", palette=\"muted\")\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "\n",
    "from ctypes import cdll, CDLL\n",
    "cdll.LoadLibrary(\"libc.so.6\")\n",
    "libc = CDLL(\"libc.so.6\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _load_audio(path, duration):\n",
    "    audio = pydub.AudioSegment.silent(duration=duration)\n",
    "    audio = audio.overlay(pydub.AudioSegment.from_file(path).set_frame_rate(22050).set_channels(1))[0:duration]\n",
    "    raw = (np.fromstring(audio._data, dtype=\"int16\") + 0.5) / (0x7FFF + 0.5)   # convert to float\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_urbansound():\n",
    "    \"\"\"Load raw audio and metadata content from the UrbanSound8K dataset.\"\"\"\n",
    "    \n",
    "    if os.path.isfile(URBAN_PATH + 'urban_meta.pkl') and os.path.isfile(URBAN_PATH + 'urban_audio.dat'):\n",
    "        rows_meta = pd.read_pickle(URBAN_PATH + 'urban_meta.pkl')\n",
    "        rows_audio = np.memmap(URBAN_PATH + 'urban_audio.dat', dtype='float32', mode='r', shape=(8732, 88200))\n",
    "        return rows_meta, rows_audio\n",
    "    \n",
    "    metadata = pd.read_csv(URBAN_PATH + 'UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "    \n",
    "    b = 0\n",
    "    batch_size = 1000\n",
    "    rows_meta = []\n",
    "    rows_audio = []\n",
    "    while len(metadata[b * batch_size:(b + 1) * batch_size]):\n",
    "        for row in metadata[b * batch_size:(b + 1) * batch_size].iterrows():\n",
    "            filename = row[1]['slice_file_name']\n",
    "            fold = row[1]['fold']\n",
    "            category = row[1]['classID']\n",
    "            category_name = row[1]['class']\n",
    "            rows_meta.append(pd.DataFrame({'filename': filename, 'fold': fold, 'category': category, 'category_name': category_name}, index=[0]))\n",
    "            rows_audio.append(_load_audio(URBAN_PATH + 'UrbanSound8K/audio/fold{}/{}'.format(fold, filename), 4000))\n",
    "        libc.malloc_trim(0)\n",
    "        b = b + 1\n",
    "        rows_meta = [pd.concat(rows_meta, ignore_index=True)]\n",
    "        rows_audio = [np.vstack(rows_audio)]\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        print 'Loaded batch {} ({} / {})'.format(b, b * batch_size, len(metadata))\n",
    "    \n",
    "    rows_meta = rows_meta[0]\n",
    "    rows_meta[['category', 'fold']] = rows_meta[['category', 'fold']].astype(int)\n",
    "    \n",
    "    rows_meta.to_pickle(URBAN_PATH + 'urban_meta.pkl')\n",
    "    mm = np.memmap(URBAN_PATH + 'urban_audio.dat', dtype='float32', mode='w+', shape=(8732, 88200))\n",
    "    mm[:] = rows_audio[0][:]\n",
    "    mm.flush()\n",
    "    del rows_audio\n",
    "    return rows_meta, mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_esc(variant):\n",
    "    \"\"\"Load raw audio and metadata content from the ESC-10/ESC-50 dataset.\"\"\"\n",
    "    \n",
    "    if variant == 10:\n",
    "        if os.path.isfile(ESC_PATH + 'esc10_meta.pkl') and os.path.isfile(ESC_PATH + 'esc10_audio.dat'):\n",
    "            rows_meta = pd.read_pickle(ESC_PATH + 'esc10_meta.pkl')\n",
    "            rows_audio = np.memmap(ESC_PATH + 'esc10_audio.dat', dtype='float32', mode='r', shape=(400, 110250))\n",
    "            return rows_meta, rows_audio\n",
    "        path = ESC_PATH + 'ESC-10'\n",
    "    else:\n",
    "        if os.path.isfile(ESC_PATH + 'esc50_meta.pkl') and os.path.isfile(ESC_PATH + 'esc50_audio.dat'):\n",
    "            rows_meta = pd.read_pickle(ESC_PATH + 'esc50_meta.pkl')\n",
    "            rows_audio = np.memmap(ESC_PATH + 'esc50_audio.dat', dtype='float32', mode='r', shape=(2000, 110250))\n",
    "            return rows_meta, rows_audio\n",
    "        path = ESC_PATH + 'ESC-50'\n",
    "    \n",
    "    rows_meta = []\n",
    "    rows_audio = []\n",
    "    category_counter=0\n",
    "    \n",
    "    for directory in sorted(os.listdir('{0}'.format(path))):\n",
    "        directory = '{0}/{1}'.format(path, directory)        \n",
    "        if not (os.path.isdir(directory) and os.path.basename(directory)[0:3].isdigit()):\n",
    "            continue\n",
    "        print('Parsing ' + directory)\n",
    "        for clip in sorted(os.listdir(directory)):\n",
    "            if clip[-3:] != 'ogg':\n",
    "                continue\n",
    "            filepath = '{0}/{1}'.format(directory, clip)\n",
    "            filename = os.path.basename(filepath)\n",
    "            fold = filename[0]\n",
    "            category = category_counter\n",
    "            category_name = os.path.dirname(filepath).split('/')[-1]\n",
    "            rows_meta.append(pd.DataFrame({'filename': filename, 'fold': fold, 'category': category, 'category_name': category_name}, index=[0]))\n",
    "            rows_audio.append(_load_audio(filepath, 5000))\n",
    "        libc.malloc_trim(0)\n",
    "        rows_meta = [pd.concat(rows_meta, ignore_index=True)]\n",
    "        rows_audio = [np.vstack(rows_audio)]\n",
    "        category_counter = category_counter + 1\n",
    "    \n",
    "    rows_meta = rows_meta[0]\n",
    "    rows_meta[['category', 'fold']] = rows_meta[['category', 'fold']].astype(int)\n",
    "    \n",
    "    if variant == 10:\n",
    "        rows_meta.to_pickle(ESC_PATH + 'esc10_meta.pkl')\n",
    "        mm = np.memmap(ESC_PATH + 'esc10_audio.dat', dtype='float32', mode='w+', shape=(400, 110250))\n",
    "    else:\n",
    "        rows_meta.to_pickle(ESC_PATH + 'esc50_meta.pkl')\n",
    "        mm = np.memmap(ESC_PATH + 'esc50_audio.dat', dtype='float32', mode='w+', shape=(2000, 110250))\n",
    "    mm[:] = rows_audio[0][:]\n",
    "    mm.flush()\n",
    "    del rows_audio\n",
    "    return rows_meta, mm\n",
    "\n",
    "    return rows_meta, rows_audio[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _extract_segments(args):\n",
    "    clip, filename, fold, category, category_name, augmented, frames = args\n",
    "\n",
    "    # Due to an off-by-one bug which has not been caught earlier,\n",
    "    # actually both variants (long and short) use the same\n",
    "    # overlap setting (half of window size) - whereas different settings\n",
    "    # were mentioned in the paper.\n",
    "    #\n",
    "    # The code below has been already cleaned up to reflect those changes.\n",
    "    #\n",
    "    # Apart from that, for reproducibility purposes it is required that\n",
    "    # librosa v0.3.1 is used, as further versions drastically change\n",
    "    # the delta computations.\n",
    "    \n",
    "    FRAMES_PER_SEGMENT = frames - 1  # 41 frames ~= 950 ms segment length @ 22050 Hz\n",
    "    WINDOW_SIZE = 512 * FRAMES_PER_SEGMENT   # 23 ms per frame @ 22050 Hz\n",
    "    STEP_SIZE = 512 * FRAMES_PER_SEGMENT // 2\n",
    "    BANDS = 60\n",
    "    \n",
    "    s = 0\n",
    "    segments = []\n",
    "\n",
    "    normalization_factor = 1 / np.max(np.abs(clip)) \n",
    "    clip = clip * normalization_factor\n",
    "\n",
    "    while len(clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]) == WINDOW_SIZE:\n",
    "        signal = clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(signal, sr=22050, n_fft=1024, hop_length=512, n_mels=BANDS)\n",
    "        logspec = librosa.logamplitude(melspec)\n",
    "        logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "        logspec = pd.DataFrame(data=logspec, dtype='float32', index=[0], columns=list('logspec_b{}_f{}'.format(i % BANDS, i / BANDS) for i in range(np.shape(logspec)[1])))\n",
    "\n",
    "        if np.mean(logspec.as_matrix()) > -70.0:   # drop silent frames\n",
    "            segment_meta = pd.DataFrame({'filename': filename, 'fold': fold, 'category': category, 'category_name': category_name,\n",
    "                                        's_begin': s * STEP_SIZE, 's_end': s * STEP_SIZE + WINDOW_SIZE, 'augmented': augmented}, index=[0])\n",
    "            segments.append(pd.concat((segment_meta, logspec), axis=1))\n",
    "        s = s + 1\n",
    "\n",
    "    segments = pd.concat(segments, ignore_index=True)\n",
    "    libc.malloc_trim(0)\n",
    "    return segments\n",
    "    \n",
    "def _augment(audio, category_name):\n",
    "    limits = ((0, 0), (1.0, 1.0))   # pitch shift in half-steps, time stretch\n",
    "    # ESC-10:\n",
    "    if category_name == '001 - Dog bark': limits = ((-4, 4), (0.95, 1.1))    \n",
    "    if category_name == '003 - Sea waves': limits = ((0, 0), (0.9, 1.2))  \n",
    "    if category_name == '004 - Baby cry': limits = ((-3, 6), (0.8, 1.3))    \n",
    "    if category_name == '006 - Person sneeze': limits = ((-4, 4), (0.9, 1.2))    \n",
    "    if category_name == '007 - Helicopter': limits = ((0, 0), (0.9, 1.2))    \n",
    "    if category_name == '008 - Chainsaw': limits = ((-4, 2), (0.9, 1.2))    \n",
    "    if category_name == '009 - Rooster': limits = ((-3, 2), (0.95, 1.1))\n",
    "    \n",
    "    # UrbanSound8K:\n",
    "    if category_name == 'car_horn': limits = ((-2, 2), (0.9, 1.1))\n",
    "    if category_name == 'children_playing': limits = ((-2, 3), (0.9, 1.2))\n",
    "    if category_name == 'dog_bark': limits = ((-4, 4), (0.95, 1.1))        \n",
    "    if category_name == 'drilling': limits = ((-1, 1), (0.9, 1.1))\n",
    "    if category_name == 'gun_shot': limits = ((-1, 1), (0.9, 1.1))\n",
    "    if category_name == 'siren': limits = ((-2, 3), (0.9, 1.2))\n",
    "    if category_name == 'street_music': limits = ((-6, 6), (0.9, 1.2))\n",
    "    \n",
    "    pitch_shift = np.random.randint(limits[0][1], limits[0][1] + 1)\n",
    "    time_stretch = np.random.random() * (limits[1][1] - limits[1][0]) + limits[1][0]\n",
    "    time_shift = np.random.randint(22050)\n",
    "    \n",
    "    return np.hstack((np.zeros((time_shift)),\n",
    "                      librosa.effects.time_stretch(librosa.effects.pitch_shift(audio, 22050, pitch_shift), time_stretch)))\n",
    "        \n",
    "\n",
    "def extract_features(meta, audio, augmentations=0, frames=41):\n",
    "    np.random.seed(20150520)\n",
    "    batch_size = 100\n",
    "    segments = []\n",
    "    for b in range(len(audio) // batch_size + 1):\n",
    "        start = b * batch_size\n",
    "        end = (b + 1) * batch_size\n",
    "        if end > len(audio):\n",
    "            end = len(audio)\n",
    "        \n",
    "        segments.extend(Parallel(n_jobs=CPU_COUNT)(delayed(_extract_segments)((\n",
    "                audio[i, :],\n",
    "                meta.loc[i, 'filename'],\n",
    "                meta.loc[i, 'fold'],\n",
    "                meta.loc[i, 'category'],\n",
    "                meta.loc[i, 'category_name'],\n",
    "                0,\n",
    "                frames\n",
    "            )) for i in range(start, end)))\n",
    "        for _ in range(augmentations):\n",
    "            segments.extend(Parallel(n_jobs=CPU_COUNT)(delayed(_extract_segments)((\n",
    "                    _augment(audio[i, :], meta.loc[i, 'category_name']),\n",
    "                    meta.loc[i, 'filename'],\n",
    "                    meta.loc[i, 'fold'],\n",
    "                    meta.loc[i, 'category'],\n",
    "                    meta.loc[i, 'category_name'],\n",
    "                    1,\n",
    "                    frames\n",
    "                )) for i in range(start, end)))\n",
    "        segments = [pd.concat(segments, ignore_index=True)]\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        print '{} / {}'.format(end, len(audio))\n",
    "    return segments[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_percentage(number):\n",
    "    return int(number * 1000) / 10.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
